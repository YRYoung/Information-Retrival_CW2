-
  CNN:
    activation: leaky_relu
    batchNorm:
      - 1
      - 1
      - 1
    denseUnit:
      - 512
      - 128
    kernels:
      - 3
      - 3
      - 3
    layers:
      - 16
      - 32
      - 32
    maxPool:
      - 1
      - 1
      - 0
    stride:
      - 1
      - 1
      - 1
  general:
    displayNet: false
    seed: 0
  training:
    attention: true
    2CNN: true
    bce : 0.1
    cv: 11
    decay: -7
    dropRate: 0
    learning_rate: 9.e-3
    init_epoch: -1
    train: true
    batch_size: 256
    passages_per_query: 20
    list_mle: 0.5
  note: 'remove list_mle, proven useless, use attention, also used sigmoid intead of sign to map output to [0, 1]'
