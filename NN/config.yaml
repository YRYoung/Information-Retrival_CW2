CNN:
  activation: leaky_relu
  batchNorm:
    - 1
    - 1
    - 1
  denseUnit:
    - 512
    - 128
  kernels:
    - 3
    - 3
    - 3
  layers:
    - 16
    - 32
    - 32
  maxPool:
    - 1
    - 1
    - 0
  stride:
    - 1
    - 1
    - 1
general:
  displayNet: true
  seed: 0
training:
  cv: 1
  decay: -4
  dropRate: 0.3
  learning_rate: 5.e-3
  init_epoch: -1
  train: true
  batch_size: 7
  passages_per_query: 13

