{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dae2114d",
   "metadata": {},
   "source": [
    "\n",
    "LambdaMART Model (LM) (25 marks)\n",
    "-------------------------------------------------\n",
    "https://www.analyticsvidhya.com/blog/2019/02/flair-nlp-library-python/\n",
    "https://xgboost.readthedocs.io/en/stable/python/python_intro.html#data-interface\n",
    "\n",
    "Use the LambdaMART learning to rank algorithm (a variant of LambdaRank we have learned in the class)\n",
    "from XGBoost gradient boosting library to learn a model that can re-rank passages.\n",
    "\n",
    "command XGBoost to use LambdaMART algorithm for ranking\n",
    "by setting the appropriate value to the objective parameter as described in the documentation\n",
    "\n",
    "carry out hyperparameter tuning in this task\n",
    "--------------------------------------------------\n",
    "Report:\n",
    "\n",
    "    - describe the methodology used in deriving the best performing model.\n",
    "    - report the performance of your model on the validation data with metrics from eval.py\n",
    "    \n",
    "    - Describe:\n",
    "    \n",
    "        1. how you perform input processing\n",
    "        2. the representation/features used as input\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69ccb4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from icecream import ic\n",
    "\n",
    "from huepy import *\n",
    "from eval import init_evaluator, eval_per_query, eval_dataframe\n",
    "from utils import map_location, queries_embeddings, train_raw_df, load_passages_tensors, train_debug_df, val_raw_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c333ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, dataframe: pd.DataFrame, batch_size, p_tensors):\n",
    "        self.current_pth = -1\n",
    "        self.p_tensors = p_tensors\n",
    "        self.q_tensors = torch.load(queries_embeddings, map_location=map_location)\n",
    "        self.df = dataframe.sort_values(by=['pid'])[['qid', 'pid', 'relevancy']]\n",
    "        self.N = len(dataframe)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = self.N // self.batch_size + 1\n",
    "        ic(self.N, self.num_batches, self.batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batches\n",
    "\n",
    "    def __iter__(self):\n",
    "        for start in range(0, self.N, self.batch_size):\n",
    "            end = min(start + self.batch_size, self.N)\n",
    "            this_batch_size = end - start\n",
    "            df = self.df.iloc[start:end]\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            queries = torch.zeros((this_batch_size, 300))\n",
    "            passages = torch.zeros((this_batch_size, 300))\n",
    "            for i, row in df.iterrows():\n",
    "                queries[i, :] = self.q_tensors[row.qid]\n",
    "                passages[i, :] = self.p_tensors[row.pid]\n",
    "\n",
    "            x = torch.stack([queries, passages], dim=2).numpy().reshape(-1, 600)\n",
    "            y = df.relevancy.values.reshape(-1)\n",
    "            yield x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c048ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_tensors = load_passages_tensors()\n",
    "x_df = pd.read_parquet(train_debug_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff81b33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_parquet(val_raw_df)\n",
    "del val_df['query']\n",
    "del val_df['passage']\n",
    "del val_df['pid']\n",
    "del val_df['p_idx']\n",
    "x_val = torch.load('./data/val_embeddings.pth')[0].reshape(-1, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551fefc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(train_raw_df)\n",
    "\n",
    "_, counts = np.unique(train_df.qid, return_counts=True)\n",
    "q_idx = np.arange(0, len(counts)).repeat(counts)\n",
    "\n",
    "train_df.loc[:, 'q_idx'] = q_idx\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8232766",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = init_evaluator(at=[3, 10, 100], x_val_handler=None, prepare_x=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa77d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "param_dicts = {\n",
    "\n",
    "    'max_depth': [10, 15, 20],\n",
    "    #     'learning_rate ': [0.1, 0.5],\n",
    "    'n_estimators': [5, 10, 15],\n",
    "    #     'booster': ['gbtree', 'dart'],\n",
    "    'gamma': [.5, 1, 2]\n",
    "\n",
    "}\n",
    "param_grid = list(ParameterGrid(param_dicts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e1abfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def cross_val(train_x, train_y, param_grid=param_grid):\n",
    "    n_splits = 5\n",
    "    cv = model_selection.GroupKFold(n_splits=n_splits)\n",
    "    at = [100]\n",
    "    all_ndcg = np.zeros(len(param_grid))\n",
    "    for count, params in enumerate(param_grid):\n",
    "        print(count, params, end='')\n",
    "\n",
    "        for i, (train_index, test_index) in enumerate(cv.split(train_x, train_y, groups=q_idx)):\n",
    "            ranker = xgb.XGBRanker(learning_rate=0.1, objective='rank:ndcg', **params)\n",
    "            ranker.fit(train_x[train_index, ...], train_y[train_index, ...], qid=q_idx[train_index, ...])\n",
    "\n",
    "            # predict\n",
    "            pred = ranker.predict(train_x[test_index, ...])\n",
    "            train_df_now = train_df.iloc[test_index, :].copy()\n",
    "\n",
    "            _, avg_ndcg = eval_dataframe(train_df_now, pred, at)\n",
    "            all_ndcg[count] += avg_ndcg\n",
    "\n",
    "            #         [print(orange(italic(f'NDCG @ {now}: {value}'))) for now, value in zip(at, avg_ndcg)]\n",
    "\n",
    "        all_ndcg[count] /= n_splits\n",
    "        print(f'\\tNDCG @ 100: {all_ndcg[count] :.5f}')\n",
    "\n",
    "    best = param_grid[np.argmax(all_ndcg)]\n",
    "    print(f'final:{best}')\n",
    "\n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "983febdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataloader = DataLoader(dataframe=train_df, batch_size=len(train_raw_df), p_tensors=passage_tensors)\n",
    "_, (x_raw, y_raw) = [(x, y) for x, y in enumerate(dataloader)][0]\n",
    "row_df = dataloader.df\n",
    "\n",
    "best = cross_val(x_raw, y_raw, param_grid)\n",
    "\n",
    "# {'gamma': 2, 'max_depth': 15, 'n_estimators': 15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb82ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_parquet(train_debug_df)\n",
    "passage_tensors = load_passages_tensors()\n",
    "dataloader = DataLoader(dataframe=df_raw, batch_size=len(df_raw), p_tensors=passage_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eebaf9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (x_raw, y_raw) = [(x, y) for x, y in enumerate(dataloader)][0]\n",
    "row_df = dataloader.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "decc503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del dataloader\n",
    "\n",
    "_, counts = np.unique(row_df.qid, return_counts=True)\n",
    "\n",
    "row_df.loc[:, 'q_idx'] = np.arange(0, len(counts)).repeat(counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4643ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=2, gpu_id=None,\n",
       "          grow_policy=None, importance_type=None, interaction_constraints=None,\n",
       "          learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=15,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, n_estimators=15, n_jobs=None,\n",
       "          num_parallel_tree=None, objective=&#x27;rank:ndcg&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRanker</label><div class=\"sk-toggleable__content\"><pre>XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=2, gpu_id=None,\n",
       "          grow_policy=None, importance_type=None, interaction_constraints=None,\n",
       "          learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=15,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, n_estimators=15, n_jobs=None,\n",
       "          num_parallel_tree=None, objective=&#x27;rank:ndcg&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=2, gpu_id=None,\n",
       "          grow_policy=None, importance_type=None, interaction_constraints=None,\n",
       "          learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=15,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, n_estimators=15, n_jobs=None,\n",
       "          num_parallel_tree=None, objective='rank:ndcg', predictor=None, ...)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('start fit')\n",
    "best = {'gamma': 2, 'max_depth': 15, 'n_estimators': 15}\n",
    "best_ranker = xgb.XGBRanker(learning_rate=0.1, objective='rank:ndcg', **best)\n",
    "best_ranker.fit(x_raw, y_raw, qid=row_df.q_idx.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "964ed8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.007259  , 0.01048165, 0.0143232 ]),\n",
       " array([0.00829592, 0.01518676, 0.03929316]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = init_evaluator(at=[3, 10, 100], x_val_handler=None, prepare_x=False)\n",
    "evaluator(best_ranker.predict(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc37ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = best_ranker.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1b90ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(pred_callback, model_name):\n",
    "    p = torch.load('./data/part1/passage.pth', map_location=map_location)\n",
    "    q = torch.load('./data/part1/query.pth', map_location=map_location)\n",
    "    df = pd.read_csv('./data/part1/candidate_passages_top1000.tsv', sep='\\t', header=None,\n",
    "                     names=['qid', 'pid', 'query', 'passage'])\n",
    "\n",
    "    df = df.sort_values(by=['pid'])[['qid', 'pid']]\n",
    "    N = len(df)\n",
    "\n",
    "    queries = torch.zeros((N, 300))\n",
    "    passages = torch.zeros((N, 300))\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        queries[i, :] = q[row.qid]\n",
    "        passages[i, :] = p[row.pid]\n",
    "\n",
    "    x = torch.stack([queries, passages], dim=2).numpy().reshape(-1, 600)\n",
    "\n",
    "    df['score'] = pred_callback(x)\n",
    "\n",
    "    group = df.groupby('qid')\n",
    "\n",
    "    dflist = []\n",
    "    for name, dff in group:\n",
    "        dff = dff.sort_values(by=['score'], ascending=False)\n",
    "\n",
    "        if len(dff) > 100:\n",
    "            dff = dff.iloc[:100, :]\n",
    "\n",
    "        dff['rank'] = np.arange(len(dff)) + 1\n",
    "        dflist.append(dff)\n",
    "\n",
    "    result = pd.concat(dflist)\n",
    "    result['A'] = ['A2'] * len(result)\n",
    "    result['model'] = [model_name] * len(result)\n",
    "    result = result.reindex(columns=['qid', 'A', 'pid', 'rank', 'score', 'model'])\n",
    "    #     result.to_csv(f'./data/part1/{model_name}.txt', sep=' ',header=False,index=False)\n",
    "    return result\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
